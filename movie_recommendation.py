# -*- coding: utf-8 -*-
"""Movie Recommendation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10sk5d4tm4u_BfrRm9BwcOc1nBActtwTO
"""

from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession

config = ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.5
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import pandas as pd
import numpy as np
import json
import re

"""<h1>Data Cleaning</h1>"""

df = pd.read_csv('movie_dataset.csv')
df.head()

df.columns

"""<h2>Delete useless columns</h2>"""

df.drop('index', axis=1, inplace=True)
df.drop('budget', axis=1, inplace=True)
df.drop('homepage', axis=1, inplace=True)
df.drop('id', axis=1, inplace=True)
df.drop('popularity', axis=1, inplace=True)
df.drop('release_date', axis=1, inplace=True)
df.drop('revenue', axis=1, inplace=True)
df.drop('runtime', axis=1, inplace=True)

df.drop('vote_average', axis=1, inplace=True)
df.drop('vote_count', axis=1, inplace=True)
df.drop('crew', axis=1, inplace=True)

df.head()

df = df.reset_index()

"""<h2>Handling Null Values</h2>"""

df.isnull().sum()

df.fillna(" ",inplace=True)

"""<h2>Merging The Columns</h2>"""

def production_companies_mergered(row):
    data = json.loads(row.production_companies)
    merged_production_companies = ""
    for i in range(len(data)):
        merged_production_companies += (data[i]['name']+" ")
    return merged_production_companies

production_companies_mergered(df.iloc[0])
# 'Ingenious Film Partners Twentieth Century Fox Film Corporation Dune Entertainment Lightstorm Entertainment '

df["production_companies"]=df.apply(production_companies_mergered,axis=1)

def production_countries_mergered(row):
    data = json.loads(row.production_countries)
    merged_production_countries = ""
    for i in range(len(data)):
        merged_production_countries += (data[i]['name']+" ")
    return merged_production_countries

production_countries_mergered(df.iloc[0])

df["production_countries"]=df.apply(production_countries_mergered,axis=1)

def spoken_languages_mergered(row):
    data = json.loads(row.spoken_languages)
    merged_spoken_languages = ""
    for i in range(len(data)):
        merged_spoken_languages += (data[i]['name']+" ")
    return merged_spoken_languages

spoken_languages_mergered(df.iloc[0])

df["spoken_languages"]=df.apply(spoken_languages_mergered,axis=1)

df.columns

def combined_features(row):
    features = ['genres', 'keywords', 'original_language', 'original_title',
       'overview', 'production_companies', 'production_countries',
       'spoken_languages', 'status', 'tagline', 'title', 'cast', 'director']
    combo_feature = ""
    for i in features:
        combo_feature += (row[i]+" ")
    
    return combo_feature



combined_features(df.iloc[0])

df["Combined_feature"] = df.apply(combined_features,axis=1)

"""<h2>Text analysis over combined features</h2>"""

import nltk
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')

from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.stem import PorterStemmer
from nltk.corpus import stopwords

def text_cleaning(combo_feature):
#     Lower the case of combined Feature
    combo_feature = combo_feature.lower()
#     Remove all the numbers
    combo_feature = re.sub(r'\d+', '', combo_feature)
#     Remove all the punctuations
    combo_feature = re.sub(r'[^\w\s]', '', combo_feature)

#     handling stopwords
    stop_words = set(stopwords.words('english'))
    tokens = word_tokenize(combo_feature)
    result = [i for i in tokens if not i in stop_words]
    combo_feature = ""
    lemmatizer=WordNetLemmatizer()
    for word in result:
         combo_feature += lemmatizer.lemmatize(word)+" "
        
    
    
#     combo_feature = " ".join(result)    
    return combo_feature
text_cleaning(df.Combined_feature.iloc[0])

df["Combined_feature"] = df["Combined_feature"].apply(text_cleaning)

df.head()

def get_title_from_index(index):
    return df[df["index"] == index]["title"].values[0]
def get_index_from_title(title):
    return df[df["title"] == title]["index"].values[0]

get_title_from_index(0)
get_index_from_title("John Carter")

"""<h2>Creating Vector Matrix</h2>"""

cv = CountVectorizer()
count_matrix=cv.fit_transform(df["Combined_feature"])

cosine_sim = cosine_similarity(count_matrix)

"""<h2>Tesing the Model</h2>"""

movie_liked_by_user = "Avatar"

liked_movie_index = cosine_sim[get_index_from_title(movie_liked_by_user)]
similar_movie = list(enumerate(liked_movie_index))
similar_movie.sort(key = lambda row: row[1],reverse=True)
for i in range(10):
    print(get_title_from_index(similar_movie[i][0]))

"""<h2>Saving The Model</h2>"""

import pickle
pickle.dump(cosine_sim,open('./movies.pkl','wb'))

df.to_csv("file2.csv")